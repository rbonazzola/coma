{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import re \n",
    "# I rename the class VTKObject as Mesh so I don't have to change the function calls in the code\n",
    "from VTK.VTKMesh import VTKObject as Mesh  #, MeshViewer, MeshViewers\n",
    "import meshio\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm # for the progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyFromVTKs(object):\n",
    "    \n",
    "    \"\"\"docstring for NumpyFromVTKs\"\"\"\n",
    "\n",
    "    def __init__(self, folders, filename_pattern=\"*/output.001.vtk\", dataset_name=\"LV_endo_100\", partition_ids=None, subj_ids=None, N_subj=None):\n",
    "        \n",
    "        '''          \n",
    "          - subj_ids: list of subject IDs to draw samples from (if None, it's all the subjects)\n",
    "          - N_subj: number of subjects to sample (if None, it's all the subjects from subj_ids)\n",
    "        '''\n",
    "        \n",
    "        self.folders = folders if isinstance(folders, list) else [folders]\n",
    "        self.filename_pattern = os.path.join(folders, filename_pattern)\n",
    "        self.regex = re.compile(self.filename_pattern.replace(\"*\",\"(.*)\"))\n",
    "        self.dataset_name = dataset_name # output directory\n",
    "        \n",
    "        self.partition_ids = partition_ids\n",
    "        self.N_subj = N_subj\n",
    "        self.subj_ids = subj_ids \n",
    "\n",
    "        self.gather_paths()\n",
    "        # self.train_vertices = self.gather_data(self.datapaths[\"train\"])\n",
    "        # self.test_vertices = self.gather_data(self.datapaths[\"test\"])\n",
    "\n",
    "        #self.save_vertices()\n",
    "\n",
    "        \n",
    "    def extract_id_from_path(self, path):\n",
    "            # compile once above\n",
    "            id = self.regex.match(path).group(1)\n",
    "            return id\n",
    "        \n",
    "        \n",
    "    def gather_paths(self, test_fraction=0.1):\n",
    "        \n",
    "        '''\n",
    "        :param opt: 'train' or 'test'\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        datapaths = []\n",
    "        for subdir_name in self.folders:\n",
    "            datapaths.extend(sorted(glob.glob(self.filename_pattern)))\n",
    "            \n",
    "        print(len(datapaths))\n",
    "            \n",
    "        if self.subj_ids is None:            \n",
    "            id_dict = {self.extract_id_from_path(x): x for x in datapaths}\n",
    "        else:\n",
    "            id_dict = {self.extract_id_from_path(x): x for x in datapaths if self.extract_id_from_path(x) in subj_ids}\n",
    "            print(len(id_dict))\n",
    "            \n",
    "        \n",
    "        if self.N_subj is not None:\n",
    "            ind_list = list(range(len(id_dict)))\n",
    "            random.shuffle(ind_list)\n",
    "            ind_list = ind_list[0:self.N_subj]\n",
    "            datapaths = [id_dict[i] for i in ind_list]\n",
    "        else:\n",
    "            datapaths = id_dict.values()\n",
    "            pass # use all the data paths\n",
    "                                        \n",
    "        self.datapaths = datapaths\n",
    "\n",
    "\n",
    "    def gather_data(self):\n",
    "        vertices = []\n",
    "\n",
    "        # tqdm: for progress bar (I think)\n",
    "        for p in tqdm(self.datapaths, unit=\"subjects\"):\n",
    "            mesh_filename = p\n",
    "            mesh = Mesh(filename=mesh_filename) # Load mesh\n",
    "            mesh = Mesh.extractSubpart(mesh, self.partition_ids)\n",
    "            vertices.append(mesh.points)\n",
    "\n",
    "        return np.array(vertices)\n",
    "\n",
    "\n",
    "    def save_vertices(self):\n",
    "\n",
    "        if not os.path.exists(self.dataset_name):\n",
    "            os.makedirs(self.dataset_name)\n",
    "\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = NumpyFromVTKs(\n",
    "  folders = \"/MULTIX/DATA/INPUT/disk_2/coma/Cardio/meshes/vtk_meshes\", \n",
    "  filename_pattern=\"*/output.001.vtk\", \n",
    "  dataset_name=\"\", subj_ids=None, N_subj=None, partition_ids=[1,2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cardiac_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:46<00:00,  1.66s/subjects]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardiac_mesh.generateNumpyDataset(\"/MULTIX/DATA/INPUT/disk_2/coma/Cardio/meshes/vtk_meshes\", \"/MULTIX/DATA/INPUT/disk_2/coma/Cardio/meshes/numpy_files/LV_all_subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_coma)",
   "language": "python",
   "name": "conda_coma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
