{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.chdir(\"/home/ubuntu/coma/\")\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import yaml\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import re\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from scipy.spatial import procrustes as procrustes\n",
    "\n",
    "import glob, os, json\n",
    "import pandas as pd\n",
    "\n",
    "from main import generate_model #, run as train\n",
    "from VTK.VTKMesh import VTKObject as Mesh\n",
    "from cardiac_mesh import CardiacMesh\n",
    "from sklearn.decomposition import PCA, IncrementalPCA as IPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions of paths and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = [\"LV\", \"RV\"]\n",
    "\n",
    "data_files = {\n",
    "    \"LV\": \"/MULTIX/DATA/INPUT/disk_2/coma/Cardio/meshes/numpy_files/LV_all_subjects/train.npy\",\n",
    "    \"LV_endo\": \"/MULTIX/DATA/INPUT/disk_2/coma/Cardio/meshes/numpy_files/LV_endo_all_subjects/LVED_all_subjects.npy\",\n",
    "    \"RV\": \"/MULTIX/DATA/INPUT/disk_2/coma/Cardio/meshes/numpy_files/RV/RV_all.npy\"\n",
    "}\n",
    "\n",
    "ids_files = {\n",
    "    \"LV\": \"/MULTIX/DATA/INPUT/disk_2/coma/Cardio/meshes/numpy_files/LV_all_subjects/LVED_all_subjects_subj_ids.txt\",\n",
    "    \"LV_endo\": \"/MULTIX/DATA/INPUT/disk_2/coma/Cardio/meshes/numpy_files/LV_endo_all_subjects/LVED_all_subjects_subj_ids.txt\",\n",
    "    \"RV\": \"/MULTIX/DATA/INPUT/disk_2/coma/Cardio/meshes/numpy_files/RV/RV_all_subject_ids.txt\"\n",
    "}\n",
    "\n",
    "# meshes_dir = \"/MULTIX/DATA/INPUT/disk_2/coma/Cardio/meshes/numpy_files/\"\n",
    "# output_dir = \"/MULTIX/DATA/INPUT/disk_2/coma/Cardio/output/\"\n",
    "# checkpoints_dir = \"{}/checkpoints\".format(output_dir)\n",
    "\n",
    "# subparts_ids = CardiacMesh.subparts_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meshes = np.load(data_files[\"LV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = [\"LV\", \"RV\"]\n",
    "reference_mesh_file = \"/MULTIX/DATA/INPUT/disk_2/coma/Cardio/meshes/vtk_meshes/1000336/output.001.vtk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assign_set(data):\n",
    "    training_ids = [(x, \"training\") for x in data.train_ids]\n",
    "    validation_ids = [(x, \"validation\") for x in data.val_ids]\n",
    "    testing_ids = [(x, \"testing\") for x in data.test_ids]\n",
    "    return dict(training_ids + testing_ids + validation_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices normalized\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "Vertices normalized\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "perf_dfs = []\n",
    "\n",
    "for partition in partitions:\n",
    "    \n",
    "  cardiac_data = CardiacMesh(\n",
    "   nTraining = 1600,\n",
    "   nVal = 200,\n",
    "   train_file = data_files[partition],\n",
    "   ids_file = ids_files[partition],\n",
    "   reference_mesh_file = reference_mesh_file,\n",
    "   pca_n_comp = [8],\n",
    "   subpart = CardiacMesh.subparts_ids[partition]\n",
    "  )  \n",
    "\n",
    "  meshes_1d_train = np.array([x.flatten() for x in cardiac_data.vertices_train])  \n",
    "  meshes_1d_val   = np.array([x.flatten() for x in cardiac_data.vertices_val])\n",
    "  meshes_1d_test  = np.array([x.flatten() for x in cardiac_data.vertices_test])\n",
    "  \n",
    "  meshes_1d  = np.concatenate((meshes_1d_train, meshes_1d_val, meshes_1d_test))\n",
    "\n",
    "  all_ids = cardiac_data.train_ids + cardiac_data.val_ids + cardiac_data.test_ids    \n",
    "\n",
    "  partition_ids = _assign_set(cardiac_data)\n",
    "\n",
    "  for n in range(1, 33):\n",
    "    \n",
    "    print(n)\n",
    "    pp = PCA(n).fit(meshes_1d_train)\n",
    "    meshes_reduced = pp.transform(meshes_1d)\n",
    "    meshes_reconstructed = pp.inverse_transform(meshes_reduced)\n",
    "  \n",
    "    mse = ((meshes_1d - meshes_reconstructed)**2).mean(axis=1)\n",
    "     \n",
    "    shuffled_ids = range(meshes_reconstructed.shape[0])\n",
    "    np.random.shuffle(shuffled_ids)        \n",
    "    mse_shuffled = ((meshes_1d - meshes_reconstructed[shuffled_ids,:])**2).mean(axis=1)\n",
    "    \n",
    "    # if n == 1: from IPython import embed; embed()\n",
    "    perf_df = pd.DataFrame({\n",
    "      \"model_id\": [\"PCA__{}__{}_comps\".format(partition, str(n))] * len(all_ids),\n",
    "      \"subject_id\": all_ids, \n",
    "      \"dataset\": [partition_ids[x] for x in all_ids],\n",
    "      \"partition\": [partition] * len(all_ids),\n",
    "      \"mse\": mse,\n",
    "      \"mse_shuffled\": mse_shuffled,\n",
    "      \"n\": [n] * len(all_ids),      \n",
    "    })     \n",
    "\n",
    "    perf_dfs.append(perf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df_all = pd.concat(perf_dfs)\n",
    "perf_df_all\n",
    "\n",
    "\n",
    "perf_df_all.to_csv(\"/MULTIX/DATA/INPUT/disk_2/coma/Cardio/output/performance_summary/PCA.csv\", index_label=\"run_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_coma)",
   "language": "python",
   "name": "conda_coma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
